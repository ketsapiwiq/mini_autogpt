import json
import think.memory as memory
import think.prompt as prompt
import utils.llm as llm
from action.action_decisions import decide, validate_json, extract_json_from_response
from action.action_execute import take_action
from utils.log import log, save_debug

fail_counter = 0

def run_think():
    thinking = think()  # takes
    print("THOUGHTS : " + thinking)
    decision = decide(thinking)
    print("DECISIONS : " + str(decision))
    evaluated_decision = evaluate_decision(thinking, decision)
    print("EVALUATED DECISION : " + str(evaluated_decision))
    take_action(evaluated_decision)


def evaluate_decision(thoughts, decision):
    # combine thoughts and decision and ask llm to evaluate the decision json and output an improved one
    history = llm.build_prompt(prompt.evaluation_prompt)
    context = f"Thoughts: {thoughts} \n Decision: {decision}"
    history.append({"role": "user", "content": context})
    response = llm.ollama_request(history)

    assistant_message = response['message']['content']

    assistant_message = extract_json_from_response(assistant_message)

    if validate_json(assistant_message):
        # Parse the JSON string
        # parsed_json = json.loads(assistant_message)
        # Pretty print the parsed JSON
        # log(json.dumps(parsed_json, indent=4, ensure_ascii=False))
        return assistant_message
    else:
        global fail_counter
        fail_counter = fail_counter + 1
        if fail_counter >= 5:
            log("Got too many bad quality responses!")
            exit(1)

        save_debug(history, response=response.json())
        log("Retry Decision as faulty JSON!")
        history.append({"role": "system", "content": "Final JSON:\n"})
        return evaluate_decision(thoughts, decision)

def think():
    """
    Performs the thinking process and returns the thoughts generated by the assistant.

    Returns:
        str: The thoughts generated by the assistant.

    Raises:
        Exception: If there is an error in the thinking process.
    """
    log("*** I am thinking... ***")
    history = llm.build_prompt(prompt.thought_prompt)

    thought_history = memory.load_thought_history()
    thought_summaries = [json.loads(item)["summary"] for item in thought_history]

    history = llm.build_context(
        history=history,
        conversation_history=thought_summaries,
        message_history=memory.load_response_history()[-2:],
        # conversation_history=telegram.get_previous_message_history(),
        # message_history=telegram.get_last_few_messages(),
    )

    history.append(
        {
            "role": "user",
            "content": "Formulate your thoughts and explain them as detailed as you can.",
        },
    )
    log("Sending request...")
    response = llm.ollama_request(history)
    log("Received response")
    if response.status_code == 200:
        # Extracting and printing the assistant's message
        thoughts = response['message']['content']
        log("*** I think I have finished thinking! *** \n")
        memory.save_thought(thoughts, context=history)
        return thoughts
    else:
        log(response.status_code)
        log(response.content)
        raise Exception
